# Database Configuration
DATABASE_URL=postgresql://user:password@localhost/ontextract_db
# Alternative: Use shared ProEthica database
# DATABASE_URL=postgresql://user:password@localhost/ai_ethical_dm

# Flask Configuration
SECRET_KEY=your_secret_key_here
FLASK_ENV=development
FLASK_APP=run.py
WTF_CSRF_ENABLED=True

# ==============================================================================
# LLM PROVIDER API KEYS
# ==============================================================================
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
DEFAULT_LLM_PROVIDER=anthropic

# ==============================================================================
# CLAUDE MODEL CONFIGURATION
# ==============================================================================
# Latest Claude models (as of January 2025):
# claude-opus-4-1-20250805 - Most capable and intelligent model
# claude-sonnet-4-20250514 - High-performance model with exceptional reasoning
# claude-3-7-sonnet-20250219 - High intelligence with extended thinking
# claude-3-5-haiku-20241022 - Fastest model for quick responses
CLAUDE_DEFAULT_MODEL=claude-sonnet-4-20250514
CLAUDE_API_VERSION=2023-06-01
CLAUDE_EMBEDDING_MODEL=claude-3-embedding

# ==============================================================================
# OPENAI MODEL CONFIGURATION
# ==============================================================================
# Latest OpenAI models (as of January 2025):
# gpt-4o - Latest multimodal model (text + vision)
# gpt-4o-mini - Cost-effective multimodal model
# gpt-4-turbo - Latest GPT-4 Turbo model
# gpt-3.5-turbo - Fast and cost-effective
OPENAI_DEFAULT_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# Alternative embedding models:
# text-embedding-3-large - Higher quality embeddings
# text-embedding-ada-002 - Legacy model

# ==============================================================================
# LLM PROVIDER CONFIGURATION
# ==============================================================================
# Priority order for LLM providers (comma-separated)
LLM_PROVIDER_PRIORITY=openai,claude

# Temperature settings for different use cases
LLM_TEMPERATURE_DEFAULT=0.7
LLM_TEMPERATURE_CREATIVE=0.9
LLM_TEMPERATURE_ANALYTICAL=0.3

# Max tokens for different use cases
LLM_MAX_TOKENS_DEFAULT=1000
LLM_MAX_TOKENS_SUMMARY=500
LLM_MAX_TOKENS_EXTENDED=4000

# Google Cloud Configuration
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account-key.json
GOOGLE_PROJECT_ID=your_google_cloud_project_id
GOOGLE_LOCATION=us-central1

# Google LangExtract Configuration
GOOGLE_LANGUAGE_SERVICE_ENABLED=True
GOOGLE_TRANSLATE_SERVICE_ENABLED=True

# File Upload Configuration
ONTEXTRACT_UPLOAD_FOLDER=uploads
MAX_CONTENT_LENGTH=16777216  # 16MB max file size
ALLOWED_EXTENSIONS=txt,pdf,docx,html,md

# Processing Configuration
ENABLE_BATCH_PROCESSING=True
MAX_CONCURRENT_JOBS=3

# RAG Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
VECTOR_DIMENSION=384
SIMILARITY_THRESHOLD=0.7

# Redis Configuration (for Celery task queue)
REDIS_URL=redis://localhost:6379/0

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/ontextract.log

# Development Configuration
DEBUG=True
TESTING=False
